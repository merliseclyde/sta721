\documentclass{article}
\usepackage{fullpage,amsmath,amssymb,array,comment,eucal}
\pagestyle{empty}
\input{../macros}
\begin{document}
{\bf STA721 \hfill Homework 5}

\vspace{.5in}


\begin{enumerate}
\item Show that $\P_{\X^T} = (\X^T\X) (\X^T\X)^{-}$ is a projection 
  onto the column space of $\X^T$  where $(\X^T\X)^{-}$ is a generalized inverse.
  Does this depend on the actual choice of generalized inverse?
  (explain)  Is this an orthogonal projection?

\item Show that for an estimable function $\lambda = \X^T \a$  with
  $\a \in C(\X)$ that $(\I - \P_{\X^T}) \lambdab = \zero$
\item Using the spectral decomposition of $(\X^T\X)$ and the
  Moore-Penrose generalized inverse (see class notes) find a simple
  expression for $\I - \P_{\X^T}$ in terms of a reduced set of the eigenvectors of
  $\X^T\X$.

\item If $\X$ is full column rank, does a Best Linear Unbiased
  Prediction (BLUP) exist for all $\x_*
  \in \bbR^{p+1}$ ($\x_* \neq \zero$)?  Prove or Disprove.
\item (optional) Write a function in \R \ to  find the projection $(\I - \P_{\X^T})\lambdab$ 
  with the design matrix (with intercept) and lambda (vector or
  matrix) as input.   (post the {\tt R } code on Piazza)
  Apply your function  to the example from class and compare to the
 conclusions from {\tt epredict}.   What sort of tolerance do you need to
 decide if $(\I - \P_{\X^T}) \lambdab = \zero$?.   Extra challenge -
 have your function return the estimates, SE and confidence intervals!  

 \item For the Prostate data:  create ``dummy'' or indicator
   variables for the levels of the gleason
   scores and add to the dataframe  {\tt Prostate\$D7 = (gleason ==
     7)} and show that they are linearly related to the intercept.

\item  Fit a linear model of with response {\tt lpsa}  including all
  of the dummy variables and the intercept. 
What are the coefficients?  If you change the order that the dummy
variables enter the model formula, what happens to the coefficients?
If you force the intercept to be zero (add -1 to the formula) what are
the results?  


\item Using as.factor(gleason) as a predictor in {\tt lm}, what is the
  equivalent model formula using dummy variables?  See
  {\tt model.matrix} to extract the design matrix.
What are the interpretation for these coefficients?  (provide an
explanation in a couple of sentences with the actual estimates.) 

\item In the model with all dummy variables and the intercept, use the
  theorem from class to show that each of the individual coefficients
  are not estimable. 

\item (for the energetic student. otherwise optional)  The epredict function assumes that
  the intercept is always included, so any linear combination of $\b$
  always has the intercept added which means we cannot use the
  function to see if individual $\b_j$ are estimable via a $\lambdab =
  (0, 0, 1, \ldots 0)^T$. Create a new variable that is a
  column of ones {\tt Prostate\$I = rep(1, n)} and fit the model 
  using the formula {\tt lpsa} $\sim$ {\tt I + D6 + D7  + D8 + D9 -1 }
  where D7 is the dummy variable indication that the gleason score is
  7 and -1 drops the column of ones added by default.    Create a data
  frame for predicting that will let you demonstrate with epredict that none of the
  individual $\b$ are estimable.

\end{enumerate}
\end{document}

